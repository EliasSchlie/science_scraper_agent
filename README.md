# Django Project with Scientific Paper Scraper

A Django web application with automatic VPS deployment featuring a scientific paper scraper agent that extracts causal interactions from research papers.

## ğŸš€ Features

### Core Application
- Auto-deployment to VPS on push to main branch
- Modern Django 5.2+ setup
- WhiteNoise for static file serving
- Gunicorn for production serving

### Scientific Paper Scraper (`/scraper/`)
- ğŸ” AI-powered PubMed search query generation
- ğŸ“„ Automatic PDF download from open-access sources
- ğŸ¤– LLM-based extraction of causal relationships
- ğŸ“Š Real-time progress monitoring with beautiful web UI
- ğŸ’¾ Database storage of all interactions
- ğŸ¨ Modern gradient-based UI design

## ğŸ“‹ Quick Start

### 1. Clone & Install

```bash
git clone <your-repo-url>
cd andrei_django_frontend
pip install -r requirements.txt
```

### 2. Environment Setup

Create `.env` file:

```env
SECRET_KEY=your-secret-key-here
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1
CSRF_TRUSTED_ORIGINS=http://localhost:8000

# Required for scraper
NEBIUS_API_KEY=your-nebius-api-key

# Optional
BRIGHT_WEB_UNLOCKER_KEY=your-bright-data-key
```

### 3. Database Setup

```bash
python manage.py migrate
python manage.py createsuperuser
```

### 4. Run Development Server

```bash
python manage.py runserver
```

### 5. Access the Application

- **Home**: http://localhost:8000/
- **Scraper**: http://localhost:8000/scraper/
- **Admin**: http://localhost:8000/admin/

## ğŸ”¬ Scraper Usage

1. Navigate to http://localhost:8000/scraper/
2. Enter a variable of interest (e.g., "creatine", "exercise", "vitamin D")
3. Set minimum interactions to find
4. Click "Start Scraping"
5. Watch the AI agent work in real-time!

### What the Scraper Does

The agent automatically:
1. Generates intelligent PubMed search queries
2. Finds relevant scientific papers
3. Checks if papers are intervention studies
4. Downloads open-access PDFs
5. Extracts causal relationships (IV â†’ DV)
6. Stores interactions in the database

### Example Output

| Independent Variable | Effect | Dependent Variable | Reference |
|---------------------|--------|-------------------|-----------|
| Creatine supplementation | + | Muscle mass | DOI: 10.xxx |
| Exercise | - | Blood pressure | DOI: 10.yyy |

## ğŸ“ Project Structure

```
andrei_django_frontend/
â”œâ”€â”€ config/              # Django settings
â”œâ”€â”€ core/                # Core app
â”œâ”€â”€ scraper/             # Scientific paper scraper
â”‚   â”œâ”€â”€ agent/          # LangGraph agent code
â”‚   â”œâ”€â”€ templates/      # Web interface
â”‚   â”œâ”€â”€ models.py       # Database models
â”‚   â”œâ”€â”€ views.py        # API & views
â”‚   â”œâ”€â”€ services.py     # Background agent runner
â”‚   â””â”€â”€ README.md       # Detailed scraper docs
â”œâ”€â”€ scraper-agent-code/ # Original Python implementation
â”œâ”€â”€ manage.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md          # This file
```

## ğŸš€ Deployment

### Automatic Deployment to VPS

This project is configured for automatic deployment when you push to the main branch.

### Pre-deployment Checklist

1. âœ… Set environment variables on VPS (especially `NEBIUS_API_KEY`)
2. âœ… Ensure Python 3.9+ is installed
3. âœ… Configure your deployment script to run migrations
4. âœ… Set `DEBUG=False` in production
5. âœ… Configure proper `ALLOWED_HOSTS` and `CSRF_TRUSTED_ORIGINS`

### Deployment Commands (on VPS)

```bash
# Pull latest code
git pull origin main

# Install/update dependencies
pip install -r requirements.txt

# Run migrations
python manage.py migrate

# Collect static files
python manage.py collectstatic --noinput

# Restart service
sudo systemctl restart your-django-service
```

## ğŸ› ï¸ Development

### Running Tests

```bash
python manage.py test
```

### Creating Migrations

```bash
python manage.py makemigrations
python manage.py migrate
```

### Accessing Django Shell

```bash
python manage.py shell
```

## ğŸ“š Documentation

- **Scraper Detailed Docs**: See `scraper/README.md`
- **Quick Setup**: See `SCRAPER_SETUP.md`

## ğŸ”§ Configuration

### Required Environment Variables

```env
SECRET_KEY          # Django secret key
DEBUG               # True/False
ALLOWED_HOSTS       # Comma-separated hostnames
NEBIUS_API_KEY      # For AI functionality (required for scraper)
```

### Optional Environment Variables

```env
CSRF_TRUSTED_ORIGINS      # Comma-separated URLs
BRIGHT_WEB_UNLOCKER_KEY   # For paywalled papers
```

## ğŸ—„ï¸ Database

Default: SQLite (`db.sqlite3`)

For production, consider PostgreSQL:

```python
# settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'your_db_name',
        'USER': 'your_db_user',
        'PASSWORD': 'your_db_password',
        'HOST': 'localhost',
        'PORT': '5432',
    }
}
```

## ğŸ› Troubleshooting

### Scraper Not Working

**"LangChain dependencies not installed"**
- Run: `pip install -r requirements.txt`
- Ensure `langchain-nebius>=0.1.3` is installed

**"No module named 'langchain_nebius'"**
- Check that NEBIUS_API_KEY is set
- Verify package installation

### Deployment Issues

**Static files not loading**
- Run: `python manage.py collectstatic`
- Check WhiteNoise configuration

**Database errors**
- Ensure migrations are run: `python manage.py migrate`
- Check database permissions

## ğŸ“ License

See LICENSE file for details.

## ğŸ¤ Contributing

1. Create a feature branch
2. Make your changes
3. Test thoroughly
4. Push to main for auto-deployment

## ğŸ”— Links

- **Admin Panel**: `/admin/`
- **Scraper Interface**: `/scraper/`
- **API Endpoints**: `/scraper/api/`

## âš¡ Tech Stack

- **Backend**: Django 5.2+
- **AI**: LangChain, LangGraph, Nebius
- **Database**: SQLite (dev), PostgreSQL (production recommended)
- **Deployment**: Gunicorn, WhiteNoise
- **Frontend**: Vanilla JS, CSS3 (no framework needed)
- **PDF Processing**: PyMuPDF4LLM
- **APIs**: PubMed, Unpaywall, arXiv

## ğŸ¯ Future Enhancements

- [ ] Add Celery for better background task handling
- [ ] Implement job cancellation
- [ ] Add network graph visualization
- [ ] Export functionality (CSV, JSON)
- [ ] User authentication
- [ ] Search and filter interactions
- [ ] Pagination for large datasets
- [ ] Email notifications on job completion

---

Built with â¤ï¸ using Django and AI

